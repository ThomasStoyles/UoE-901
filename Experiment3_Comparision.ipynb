{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libaries \n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.llms import CTransformers\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "from random import getrandbits\n",
    "from transformers import AutoTokenizer\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "import time\n",
    "import pathlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "z:\\Uni-CE901\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "z:\\Uni-CE901\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Reading txt files\n",
    "\n",
    "# define what documents to load and where from\n",
    "class UTF8TextLoader(TextLoader):\n",
    "    def __init__(self, file_path: str, encoding: str = 'utf-8'):\n",
    "        super().__init__(file_path, encoding)\n",
    "        \n",
    "loader = DirectoryLoader(\"./\", glob=\"*.txt\", loader_cls=UTF8TextLoader)\n",
    "\n",
    "# interpret information in the documents\n",
    "documents = loader.load()\n",
    "splitter = CharacterTextSplitter()\n",
    "texts = splitter.split_documents(documents)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'})\n",
    "\n",
    "# create and save the local database\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "db.save_local(\"faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Anxiety_Causes.txt, Tokens: 271\n",
      "File: Anxiety_HelpingFriends.txt, Tokens: 950\n",
      "WARNING: Anxiety_HelpingFriends.txt exceeds the maximum token limit of 512\n",
      "File: Anxiety_PanicAttacks.txt, Tokens: 117\n",
      "File: Anxiety_symptoms.txt, Tokens: 204\n",
      "File: Anxiety_WhatToDo.txt, Tokens: 262\n",
      "File: Anxiety_WhatToSay.txt, Tokens: 399\n",
      "File: Depression.txt, Tokens: 1231\n",
      "WARNING: Depression.txt exceeds the maximum token limit of 512\n",
      "File: Depression_Causes.txt, Tokens: 774\n",
      "WARNING: Depression_Causes.txt exceeds the maximum token limit of 512\n",
      "File: Depression_HelpingFriends.txt, Tokens: 767\n",
      "WARNING: Depression_HelpingFriends.txt exceeds the maximum token limit of 512\n",
      "File: Depression_HowToTell&Living.txt, Tokens: 213\n",
      "File: Depression_Symptoms.txt, Tokens: 271\n",
      "File: Depression_Treatment&Doctor.txt, Tokens: 207\n",
      "File: Depression_Treatments.txt, Tokens: 1231\n",
      "WARNING: Depression_Treatments.txt exceeds the maximum token limit of 512\n",
      "File: Depression_Types.txt, Tokens: 519\n",
      "WARNING: Depression_Types.txt exceeds the maximum token limit of 512\n",
      "File: Depression_WhatToSay.txt, Tokens: 512\n",
      "File: Depression_WhenToSeeDoctor&Treatments.txt, Tokens: 207\n",
      "File: Depression_WhenToSeeDoctor.txt, Tokens: 207\n",
      "File: Stress_Causes.txt, Tokens: 373\n",
      "File: Stress_HelpingFriends.txt, Tokens: 491\n",
      "File: Stress_Symptoms.txt, Tokens: 427\n",
      "File: Stress_WhatIsIt.txt, Tokens: 128\n",
      "File: Stress_WhatToDo.txt, Tokens: 770\n",
      "WARNING: Stress_WhatToDo.txt exceeds the maximum token limit of 512\n"
     ]
    }
   ],
   "source": [
    "# Set the path to where you have the text files\n",
    "directory_path = r\"Z:\\Uni-CE901\\22-24_CE901-CE911-CF981-SU_stoyles_thomas\\Data\" # Change this to your directory\n",
    "\n",
    "# Initialize the tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\") # Change if you wish to test other tokenizers\n",
    "\n",
    "def count_tokens_in_file(file_path, tokenizer):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "def check_tokens_in_directory(directory_path, tokenizer, max_tokens=512):\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            num_tokens = count_tokens_in_file(file_path, tokenizer)\n",
    "            print(f\"File: {file_name}, Tokens: {num_tokens}\")\n",
    "            if num_tokens > max_tokens:\n",
    "                print(f\"WARNING: {file_name} exceeds the maximum token limit of {max_tokens}\")\n",
    "\n",
    "# Check token counts in the directory\n",
    "check_tokens_in_directory(directory_path, tokenizer, max_tokens=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_tokens(text, max_tokens, tokenizer):\n",
    "    tokens = tokenizer.encode(text, truncation=True, max_length=max_tokens)\n",
    "    return tokenizer.decode(tokens[:max_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "z:\\Uni-CE901\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# prepare the template we will use when prompting the response\n",
    "template = \"\"\"Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "# load the language model (Editing model to find best and tokens)\n",
    "config = {'max_new_tokens': 512, 'temperature': 0.01}\n",
    "llm = Ollama(model=\"llama3\") # Use Ollama website for more models https://ollama.com/library\n",
    "\n",
    "# Enable dangerous deserialization if available\n",
    "if hasattr(llm, 'allow_dangerous_deserialization'):\n",
    "    llm.allow_dangerous_deserialization = True\n",
    "\n",
    "# load the interpreted information from the local database\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'})\n",
    "db = FAISS.load_local(\"faiss\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# prepare a version of the llm pre-loaded with the local content\n",
    "retriever = db.as_retriever(search_kwargs={'k': 5}) # Max number of documents to read (k)\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['context', 'question'])\n",
    "\n",
    "QA_LLM = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                     chain_type='stuff',\n",
    "                                     retriever=retriever,\n",
    "                                     return_source_documents=True,\n",
    "                                     chain_type_kwargs={'prompt': prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining query\n",
    "\n",
    "def query(models, question):\n",
    "    model_names = {}\n",
    "    model_results = {}\n",
    "\n",
    "    for model in models:\n",
    "        model_path = model.combine_documents_chain.llm_chain.llm.model\n",
    "        model_name = pathlib.Path(model_path).name\n",
    "        \n",
    "        # Generate a random key for storing results\n",
    "        rand_key = getrandbits(32)\n",
    "        \n",
    "        time_start = time.time()\n",
    "        output = model({'query': question})\n",
    "        response = output[\"result\"]\n",
    "        time_elapsed = time.time() - time_start\n",
    "\n",
    "        # Store the model name and result in dictionaries\n",
    "        model_names[rand_key] = model_name\n",
    "        model_results[rand_key] = response\n",
    "\n",
    "        # still display each model's response time if needed\n",
    "        display(HTML(f'<code>{model_name} response time: {time_elapsed:.02f} sec</code>'))\n",
    "\n",
    "    # Randomize the order of model results to avoid bias\n",
    "    model_results = dict(sorted(model_results.items()))\n",
    "\n",
    "    return model_names, model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking best model from the chosen options\n",
    "\n",
    "def evaluate_responses(model_results):\n",
    "    print(\"Please evaluate the following responses and pick the best one:\")\n",
    "    \n",
    "    for key, response in model_results.items():\n",
    "        print(f\"Response {key}: {response}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    chosen_key = int(input(\"Enter the key of the best response: \"))\n",
    "    return chosen_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What to say when model choosen\n",
    "def main(models, question):\n",
    "    model_names, model_results = query(models, question)\n",
    "    chosen_key = evaluate_responses(model_results)\n",
    "    \n",
    "    print(f\"The chosen model is: {model_names[chosen_key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "z:\\Uni-CE901\\.venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<code>llama3 response time: 34.45 sec</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<code>llama3.1 response time: 25.89 sec</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please evaluate the following responses and pick the best one:\n",
      "Response 3141402879: According to the text, the symptoms of Depression can be categorized into three types:\n",
      "\n",
      "1. **Psychological Symptoms**:\n",
      "\t* Continuous low mood or sadness\n",
      "\t* Feeling hopeless and helpless\n",
      "\t* Having low self-esteem\n",
      "\t* Feeling tearful\n",
      "\t* Feeling guilt-ridden\n",
      "\t* Feeling irritable and intolerant of others\n",
      "\t* Having no motivation or interest in things\n",
      "\t* Finding it difficult to make decisions\n",
      "\t* Not getting any enjoyment out of life\n",
      "\t* Feeling anxious or worried\n",
      "\t* Having suicidal thoughts or thoughts of harming yourself\n",
      "2. **Physical Symptoms**:\n",
      "\t* Moving or speaking more slowly than usual\n",
      "\t* Changes in appetite or weight (usually decreased, but sometimes increased)\n",
      "\t* Constipation\n",
      "\t* Unexplained aches and pains\n",
      "\t* Lack of energy\n",
      "\t* Low sex drive (loss of libido)\n",
      "\t* Disturbed sleep – for example, finding it difficult to fall asleep at night or waking up very early in the morning\n",
      "3. **Psychological Symptoms that may not be immediately apparent**:\n",
      "\t* Difficulty concentrating or making decisions\n",
      "\t* Feeling disconnected from others or feeling isolated\n",
      "\n",
      "It's worth noting that these symptoms can vary from person to person and may not always be present all the time. If you're experiencing any of these symptoms, it's essential to seek help from a healthcare professional.\n",
      "--------------------------------------------------------------------------------\n",
      "Response 3973660401: According to the text, the psychological symptoms of depression include:\n",
      "\n",
      "* Continuous low mood or sadness\n",
      "* Feeling hopeless and helpless\n",
      "* Having low self-esteem\n",
      "* Feeling tearful\n",
      "* Feeling guilt-ridden\n",
      "* Feeling irritable and intolerant of others\n",
      "* Having no motivation or interest in things\n",
      "* Finding it difficult to make decisions\n",
      "* Not getting any enjoyment out of life\n",
      "* Feeling anxious or worried\n",
      "* Having suicidal thoughts or thoughts of harming yourself\n",
      "\n",
      "The physical symptoms include:\n",
      "\n",
      "* Moving or speaking more slowly than usual\n",
      "* Changes in appetite or weight (usually decreased, but sometimes increased)\n",
      "* Constipation\n",
      "* Unexplained aches and pains\n",
      "* Lack of energy\n",
      "* Low sex drive (loss of libido)\n",
      "* Disturbed sleep – for example, finding it difficult to fall asleep at night or waking up very early in the morning\n",
      "\n",
      "The social symptoms include:\n",
      "\n",
      "* Avoiding contact with friends and taking part in fewer social activities\n",
      "* Neglecting your hobbies and interests\n",
      "* Having difficulties in your home, work, or relationships\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the symptoms of Depression?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Run the evaluation\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(models, question)\u001b[0m\n\u001b[0;32m      3\u001b[0m model_names, model_results \u001b[38;5;241m=\u001b[39m query(models, question)\n\u001b[0;32m      4\u001b[0m chosen_key \u001b[38;5;241m=\u001b[39m evaluate_responses(model_results)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe chosen model is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_names[chosen_key]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "# Instantiate the models separately\n",
    "QA_LLM1 = RetrievalQA.from_chain_type(\n",
    "    llm=Ollama(model=\"llama3\"),\n",
    "    chain_type='stuff',\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={'prompt': prompt}\n",
    ")\n",
    "\n",
    "QA_LLM2 = RetrievalQA.from_chain_type(\n",
    "    llm=Ollama(model=\"llama3.1\"),\n",
    "    chain_type='stuff',\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={'prompt': prompt}\n",
    ")\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [QA_LLM1, QA_LLM2]\n",
    "\n",
    "# The question you wish to ask\n",
    "question = \"What are the symptoms of Depression?\"\n",
    "\n",
    "# Run the evaluation\n",
    "main(models, question)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
