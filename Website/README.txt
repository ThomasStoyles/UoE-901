This is the model put into an website which works locally. The website is not yet published due to publishing costs however there are plans to do this in the future. 
To get the website to work you will need to install the requirements.txt file. Once installed you will also need to pull the llama3 model from the Ollama library. 
To do this CD into the website files and use the following code in the terminal of your IED: ollama pull llama3 
If this does not work please see this link and follow the instructions here https://ollama.com/library/llama3

Once everything is installed in the IED terminal type: python3 app.py and allow the website to load locally. Once loaded you can visit the local address of your PC, 
which will be displayed in the terminal, and you can interact with the website.